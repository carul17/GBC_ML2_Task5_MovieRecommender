{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender Systems\n",
    "\n",
    "This notebook implements various movie recommendation approaches:\n",
    "1. Popularity-based\n",
    "2. Content-based Filtering\n",
    "3. Collaborative Filtering\n",
    "4. Matrix Factorization\n",
    "5. Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "import torch\n",
    "import warnings\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "from functools import lru_cache\n",
    "from typing import List, Tuple, Dict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup device and optimizations for Apple Silicon\n",
    "device = torch.device('mps')\n",
    "torch.backends.mps.enable_fallback_kernels = True\n",
    "print(f\"Using Apple Metal device: {device}\")\n",
    "\n",
    "# Tensor pool for memory reuse\n",
    "class TensorPool:\n",
    "    def __init__(self):\n",
    "        self._tensors: Dict[Tuple, torch.Tensor] = {}\n",
    "        \n",
    "    def get_tensor(self, shape: Tuple[int, ...], dtype=torch.float16) -> torch.Tensor:\n",
    "        key = (shape, dtype)\n",
    "        if key not in self._tensors:\n",
    "            self._tensors[key] = torch.empty(shape, dtype=dtype, device=device)\n",
    "        return self._tensors[key]\n",
    "    \n",
    "    def clear(self):\n",
    "        self._tensors.clear()\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "# Advanced caching with memory management\n",
    "class RecommendationCache:\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "        self.tensor_pool = TensorPool()\n",
    "    \n",
    "    @lru_cache(maxsize=1000)\n",
    "    def get_movie_features(self, movie_idx):\n",
    "        return self.latent_matrix_gpu[movie_idx]\n",
    "    \n",
    "    def get(self, key):\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        if len(self.cache) >= self.max_size:\n",
    "            # Remove oldest items\n",
    "            while len(self.cache) >= self.max_size * 0.8:  # Clear 20% when full\n",
    "                self.cache.pop(next(iter(self.cache)))\n",
    "        self.cache[key] = value\n",
    "    \n",
    "    def clear(self):\n",
    "        self.cache.clear()\n",
    "        self.tensor_pool.clear()\n",
    "\n",
    "# Initialize global resources\n",
    "cache = RecommendationCache()\n",
    "tensor_pool = TensorPool()\n",
    "\n",
    "# Batch processing utilities\n",
    "def get_optimal_batch_size(tensor_size: int) -> int:\n",
    "    # Dynamically adjust batch size based on available memory\n",
    "    available_memory = torch.mps.get_memory_allocated()\n",
    "    return min(1024, max(32, available_memory // (tensor_size * 4)))\n",
    "\n",
    "def process_in_batches(items: List, batch_size: int, process_fn):\n",
    "    results = []\n",
    "    for i in range(0, len(items), batch_size):\n",
    "        batch = items[i:i + batch_size]\n",
    "        results.extend(process_fn(batch))\n",
    "        # Force MPS synchronization periodically\n",
    "        if i % (batch_size * 4) == 0:\n",
    "            torch.mps.synchronize()\n",
    "    return results"
   ]
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pandas for efficient memory usage\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Custom data types for memory efficiency\n",
    "ratings_dtypes = {\n",
    "    'userId': np.int32,\n",
    "    'movieId': np.int32,\n",
    "    'rating': np.float16,\n",
    "    'timestamp': np.int64\n",
    "}\n",
    "\n",
    "# Read datasets in chunks for large files\n",
    "def read_large_csv(filename, dtypes=None, chunksize=1_000_000):\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(filename, dtype=dtypes, chunksize=chunksize):\n",
    "        chunks.append(chunk)\n",
    "        # Force memory cleanup\n",
    "        if len(chunks) % 10 == 0:\n",
    "            torch.mps.empty_cache()\n",
    "    return pd.concat(chunks)\n",
    "\n",
    "# Read the datasets\n",
    "movies_df = pd.read_csv('ml-latest-small/movies.csv')\n",
    "ratings_df = read_large_csv('ml-latest-small/ratings.csv', dtypes=ratings_dtypes)\n",
    "tags_df = pd.read_csv('ml-latest-small/tags.csv')\n",
    "\n",
    "# Process tags in batches\n",
    "def process_tags_in_batches(tags_df, batch_size=10_000):\n",
    "    grouped_tags = []\n",
    "    for start in range(0, len(tags_df), batch_size):\n",
    "        batch = tags_df.iloc[start:start + batch_size]\n",
    "        batch_grouped = batch.groupby('movieId')['tag'].apply(lambda x: ' '.join(x))\n",
    "        grouped_tags.append(batch_grouped)\n",
    "        torch.mps.empty_cache()\n",
    "    return pd.concat(grouped_tags).reset_index()\n",
    "\n",
    "# Merge tags efficiently\n",
    "tags_grouped = process_tags_in_batches(tags_df)\n",
    "movies_with_tags = pd.merge(movies_df, tags_grouped, on='movieId', how='left')\n",
    "movies_with_tags['tag'] = movies_with_tags['tag'].fillna('')\n",
    "\n",
    "# Clear memory\n",
    "del tags_df, tags_grouped\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Popularity-based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommender(n_recommendations=10):\n",
    "    # Calculate mean rating and number of ratings for each movie\n",
    "    movie_stats = ratings_df.groupby('movieId').agg({\n",
    "        'rating': ['count', 'mean']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns\n",
    "    movie_stats.columns = ['movieId', 'rating_count', 'rating_mean']\n",
    "    \n",
    "    # Filter movies with minimum number of ratings (e.g., 100)\n",
    "    popular_movies = movie_stats[movie_stats['rating_count'] >= 100]\n",
    "    \n",
    "    # Sort by rating mean and count\n",
    "    popular_movies = popular_movies.sort_values(['rating_mean', 'rating_count'], ascending=[False, False])\n",
    "    \n",
    "    # Get movie titles\n",
    "    recommendations = pd.merge(popular_movies, movies_df, on='movieId')\n",
    "    \n",
    "    return recommendations[['title', 'rating_mean', 'rating_count']].head(n_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer and convert to sparse GPU tensor\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies_with_tags['tag'])\n",
    "\n",
    "# Convert sparse matrix to GPU tensor efficiently\n",
    "indices = torch.tensor([tfidf_matrix.nonzero()[0], tfidf_matrix.nonzero()[1]], device=device)\n",
    "values = torch.tensor(tfidf_matrix.data, device=device, dtype=torch.float16)  # Use half precision\n",
    "tfidf_matrix_gpu = torch.sparse_coo_tensor(\n",
    "    indices=indices,\n",
    "    values=values,\n",
    "    size=tfidf_matrix.shape,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Perform SVD on GPU using torch operations\n",
    "U, S, V = torch.svd(tfidf_matrix_gpu.to_dense())  # Convert to dense for SVD\n",
    "latent_matrix_gpu = (U[:, :100] @ torch.diag(S[:100])).to(dtype=torch.float16)  # Use half precision\n",
    "\n",
    "# Cache for frequently accessed movie features\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_cached_movie_features(movie_idx):\n",
    "    return latent_matrix_gpu[movie_idx]\n",
    "\n",
    "def content_based_recommender(movie_title, n_recommendations=10):\n",
    "    # Get movie index and features from cache\n",
    "    movie_idx = movies_with_tags[movies_with_tags['title'] == movie_title].index[0]\n",
    "    query_vector = get_cached_movie_features(movie_idx)\n",
    "    \n",
    "    # Batch compute similarities using optimized operations\n",
    "    similarities = torch.nn.functional.cosine_similarity(\n",
    "        query_vector.unsqueeze(0).unsqueeze(0),\n",
    "        latent_matrix_gpu.unsqueeze(0)\n",
    "    ).squeeze()\n",
    "    \n",
    "    # Get top recommendations using MPS-optimized topk\n",
    "    _, similar_indices = similarities.topk(n_recommendations + 1)\n",
    "    similar_indices = similar_indices[1:].cpu().numpy()\n",
    "    \n",
    "    # Cache the results\n",
    "    cache.set(f\"content_{movie_title}\", similar_indices)\n",
    "    \n",
    "    return movies_with_tags.iloc[similar_indices][['title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-movie matrix\n",
    "user_movie_matrix = ratings_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Perform SVD for collaborative filtering\n",
    "svd_collab = TruncatedSVD(n_components=100)\n",
    "latent_matrix_2 = svd_collab.fit_transform(user_movie_matrix)\n",
    "\n",
    "# Convert matrices to GPU tensors once\n",
    "latent_matrix_2_gpu = torch.tensor(latent_matrix_2, device=device, dtype=torch.float32)\n",
    "components_gpu = torch.tensor(svd_collab.components_, device=device, dtype=torch.float32)\n",
    "\n",
    "def collaborative_recommender(user_id, n_recommendations=10):\n",
    "    # Get user's latent features\n",
    "    user_idx = user_movie_matrix.index.get_loc(user_id)\n",
    "    user_features = latent_matrix_2_gpu[user_idx]\n",
    "    user_ratings = torch.tensor(user_movie_matrix.loc[user_id].values, device=device)\n",
    "    \n",
    "    # Calculate predicted ratings on GPU\n",
    "    predicted_ratings = torch.matmul(user_features, components_gpu)\n",
    "    \n",
    "    # Create mask for unrated movies\n",
    "    unrated_mask = (user_ratings == 0)\n",
    "    \n",
    "    # Set rated movies to negative infinity to exclude them\n",
    "    predictions = predicted_ratings.clone()\n",
    "    predictions[~unrated_mask] = float('-inf')\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = torch.topk(predictions, n_recommendations)\n",
    "    top_movie_ids = user_movie_matrix.columns[indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin(top_movie_ids)]\n",
    "    return recommended_movies[['title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Matrix Factorization using Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train SVD model\n",
    "svd_model = SVD(n_factors=100, random_state=42)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Convert SVD matrices to GPU tensors once\n",
    "svd_pu = torch.tensor(svd_model.pu, device=device, dtype=torch.float32)\n",
    "svd_qi = torch.tensor(svd_model.qi, device=device, dtype=torch.float32)\n",
    "svd_bu = torch.tensor(svd_model.bu, device=device, dtype=torch.float32)\n",
    "svd_bi = torch.tensor(svd_model.bi, device=device, dtype=torch.float32)\n",
    "svd_mu = torch.tensor([svd_model.trainset.global_mean], device=device, dtype=torch.float32)\n",
    "\n",
    "def matrix_factorization_recommender(user_id, n_recommendations=10):\n",
    "    # Get all movies\n",
    "    all_movies = movies_df['movieId'].unique()\n",
    "    \n",
    "    # Get user's rated movies\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    \n",
    "    # Get unrated movies\n",
    "    unrated_movies = np.setdiff1d(all_movies, rated_movies)\n",
    "    \n",
    "    # Get user index in SVD model\n",
    "    user_inner_id = svd_model.trainset.to_inner_uid(user_id)\n",
    "    \n",
    "    # Get movie indices in SVD model\n",
    "    movie_inner_ids = [svd_model.trainset.to_inner_iid(movie_id) for movie_id in unrated_movies]\n",
    "    \n",
    "    # Convert to GPU tensors\n",
    "    user_factors = svd_pu[user_inner_id]\n",
    "    movie_factors = svd_qi[movie_inner_ids]\n",
    "    user_bias = svd_bu[user_inner_id]\n",
    "    movie_biases = svd_bi[movie_inner_ids]\n",
    "    \n",
    "    # Calculate predictions on GPU\n",
    "    predictions = torch.matmul(user_factors, movie_factors.T) + user_bias + movie_biases + svd_mu\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = torch.topk(predictions, n_recommendations)\n",
    "    recommended_movie_ids = [unrated_movies[idx] for idx in indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]\n",
    "    return recommended_movies[['title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hybrid Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def hybrid_recommender(user_id, movie_title, n_recommendations=10):\n",
    "    # Get movie index for content-based\n",
    "    movie_idx = movies_with_tags[movies_with_tags['title'] == movie_title].index[0]\n",
    "    query_vector = get_cached_movie_features(movie_idx)\n",
    "    \n",
    "    # Get user features for collaborative\n",
    "    user_idx = user_movie_matrix.index.get_loc(user_id)\n",
    "    user_features = latent_matrix_2_gpu[user_idx]\n",
    "    user_ratings = torch.tensor(user_movie_matrix.loc[user_id].values, device=device, dtype=torch.float16)\n",
    "    \n",
    "    # Batch compute all similarities and predictions on GPU\n",
    "    content_similarities = torch.nn.functional.cosine_similarity(\n",
    "        query_vector.unsqueeze(0).unsqueeze(0),\n",
    "        latent_matrix_gpu.unsqueeze(0)\n",
    "    ).squeeze()\n",
    "    \n",
    "    collab_predictions = torch.matmul(user_features, components_gpu)\n",
    "    unrated_mask = (user_ratings == 0)\n",
    "    collab_predictions[~unrated_mask] = float('-inf')\n",
    "    \n",
    "    # Get user index in SVD model for matrix factorization\n",
    "    user_inner_id = svd_model.trainset.to_inner_uid(user_id)\n",
    "    user_factors = svd_pu[user_inner_id]\n",
    "    movie_factors = svd_qi\n",
    "    movie_biases = svd_bi\n",
    "    mf_predictions = torch.matmul(user_factors, movie_factors.T) + svd_bu[user_inner_id] + movie_biases + svd_mu\n",
    "    \n",
    "    # Normalize scores to [0,1] range\n",
    "    content_scores = (content_similarities - content_similarities.min()) / (content_similarities.max() - content_similarities.min())\n",
    "    collab_scores = (collab_predictions - collab_predictions[unrated_mask].min()) / (collab_predictions[unrated_mask].max() - collab_predictions[unrated_mask].min())\n",
    "    mf_scores = (mf_predictions - mf_predictions.min()) / (mf_predictions.max() - mf_predictions.min())\n",
    "    \n",
    "    # Combine scores with weights\n",
    "    combined_scores = (content_scores * 0.3 + collab_scores * 0.4 + mf_scores * 0.3)\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = combined_scores.topk(n_recommendations)\n",
    "    indices = indices.cpu().numpy()\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df.iloc[indices][['title', 'genres']]\n",
    "    recommended_movies['scores'] = combined_scores[indices].cpu().numpy()\n",
    "    recommended_movies['content_score'] = content_scores[indices].cpu().numpy()\n",
    "    recommended_movies['collab_score'] = collab_scores[indices].cpu().numpy()\n",
    "    recommended_movies['mf_score'] = mf_scores[indices].cpu().numpy()\n",
    "    \n",
    "    # Cache the results\n",
    "    cache.set(f\"hybrid_{user_id}_{movie_title}\", indices)\n",
    "    \n",
    "    return recommended_movies.sort_values('scores', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "print(\"Popular Movies:\")\n",
    "print(popularity_recommender())\n",
    "\n",
    "print(\"\\nContent-based Recommendations for 'Toy Story (1995)':\")\n",
    "print(content_based_recommender('Toy Story (1995)'))\n",
    "\n",
    "print(\"\\nCollaborative Filtering Recommendations for user 1:\")\n",
    "print(collaborative_recommender(1))\n",
    "\n",
    "print(\"\\nMatrix Factorization Recommendations for user 1:\")\n",
    "print(matrix_factorization_recommender(1))\n",
    "\n",
    "print(\"\\nHybrid Recommendations for user 1 and 'Toy Story (1995)':\")\n",
    "print(hybrid_recommender(1, 'Toy Story (1995)'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
