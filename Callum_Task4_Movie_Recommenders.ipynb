{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender Systems\n",
    "\n",
    "This notebook implements various movie recommendation approaches:\n",
    "1. Popularity-based\n",
    "2. Content-based Filtering\n",
    "3. Collaborative Filtering\n",
    "4. Matrix Factorization\n",
    "5. Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "import torch\n",
    "import warnings\n",
    "import asyncio\n",
    "from functools import lru_cache\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup device and optimizations for Apple Silicon\n",
    "device = torch.device('mps')\n",
    "torch.backends.mps.enable_fallback_kernels = True\n",
    "print(f\"Using Apple Metal device: {device}\")\n",
    "\n",
    "# Advanced caching mechanism\n",
    "class RecommendationCache:\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.cache = {}\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    @lru_cache(maxsize=1000)\n",
    "    def get_movie_features(self, movie_idx):\n",
    "        return self.latent_matrix_gpu[movie_idx]\n",
    "    \n",
    "    def get(self, key):\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        if len(self.cache) >= self.max_size:\n",
    "            self.cache.pop(next(iter(self.cache)))\n",
    "        self.cache[key] = value\n",
    "\n",
    "cache = RecommendationCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasets\n",
    "movies_df = pd.read_csv('ml-latest-small/movies.csv')\n",
    "ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "tags_df = pd.read_csv('ml-latest-small/tags.csv')\n",
    "\n",
    "# Merge tags for each movie\n",
    "tags_grouped = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "movies_with_tags = pd.merge(movies_df, tags_grouped, on='movieId', how='left')\n",
    "movies_with_tags['tag'] = movies_with_tags['tag'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Popularity-based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommender(n_recommendations=10):\n",
    "    # Calculate mean rating and number of ratings for each movie\n",
    "    movie_stats = ratings_df.groupby('movieId').agg({\n",
    "        'rating': ['count', 'mean']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns\n",
    "    movie_stats.columns = ['movieId', 'rating_count', 'rating_mean']\n",
    "    \n",
    "    # Filter movies with minimum number of ratings (e.g., 100)\n",
    "    popular_movies = movie_stats[movie_stats['rating_count'] >= 100]\n",
    "    \n",
    "    # Sort by rating mean and count\n",
    "    popular_movies = popular_movies.sort_values(['rating_mean', 'rating_count'], ascending=[False, False])\n",
    "    \n",
    "    # Get movie titles\n",
    "    recommendations = pd.merge(popular_movies, movies_df, on='movieId')\n",
    "    \n",
    "    return recommendations[['movieId', 'title', 'rating_mean', 'rating_count']].head(n_recommendations) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer and convert to dense GPU tensor\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies_with_tags['tag'])\n",
    "\n",
    "# Convert sparse matrix to dense GPU tensor directly\n",
    "tfidf_matrix_gpu = torch.tensor(tfidf_matrix.toarray(), device=device, dtype=torch.float32)  # Use full precision for SVD\n",
    "\n",
    "# Perform SVD on GPU using torch operations\n",
    "U, S, V = torch.svd(tfidf_matrix_gpu)  # Already dense\n",
    "latent_matrix_gpu = (U[:, :100] @ torch.diag(S[:100])).to(device=device)  # Keep in full precision for stability\n",
    "\n",
    "# Cache for frequently accessed movie features\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_cached_movie_features(movie_idx):\n",
    "    return latent_matrix_gpu[movie_idx]\n",
    "\n",
    "def content_based_recommender(movie_title, n_recommendations=10):\n",
    "    # Get movie index and features from cache\n",
    "    movie_idx = movies_with_tags[movies_with_tags['title'] == movie_title].index[0]\n",
    "    query_vector = get_cached_movie_features(movie_idx)\n",
    "    \n",
    "    # Batch compute similarities using optimized operations\n",
    "    similarities = torch.nn.functional.cosine_similarity(\n",
    "        query_vector.unsqueeze(0).unsqueeze(0),\n",
    "        latent_matrix_gpu.unsqueeze(0)\n",
    "    ).squeeze()\n",
    "    \n",
    "    # Get top recommendations using MPS-optimized topk\n",
    "    _, similar_indices = similarities.topk(n_recommendations + 1)\n",
    "    similar_indices = similar_indices[1:].cpu().numpy()\n",
    "    \n",
    "    # Cache the results\n",
    "    cache.set(f\"content_{movie_title}\", similar_indices)\n",
    "    \n",
    "    recommendations = movies_with_tags.iloc[similar_indices][['movieId', 'title', 'genres']]                                                                      \n",
    "    recommendations['title'] = recommendations['title'].str.ljust(50)                                                                                   \n",
    "    return recommendations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-movie matrix\n",
    "user_movie_matrix = ratings_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Perform SVD for collaborative filtering\n",
    "svd_collab = TruncatedSVD(n_components=100)\n",
    "latent_matrix_2 = svd_collab.fit_transform(user_movie_matrix)\n",
    "\n",
    "# Convert matrices to GPU tensors once\n",
    "latent_matrix_2_gpu = torch.tensor(latent_matrix_2, device=device, dtype=torch.float32)\n",
    "components_gpu = torch.tensor(svd_collab.components_, device=device, dtype=torch.float32)\n",
    "\n",
    "def collaborative_recommender(user_id, n_recommendations=10):\n",
    "    # Get user's latent features\n",
    "    user_idx = user_movie_matrix.index.get_loc(user_id)\n",
    "    user_features = latent_matrix_2_gpu[user_idx]\n",
    "    user_ratings = torch.tensor(user_movie_matrix.loc[user_id].values, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # Calculate predicted ratings on GPU\n",
    "    predicted_ratings = torch.matmul(user_features, components_gpu)\n",
    "    \n",
    "    # Create mask for unrated movies\n",
    "    unrated_mask = (user_ratings == 0)\n",
    "    \n",
    "    # Set rated movies to negative infinity to exclude them\n",
    "    predictions = predicted_ratings.clone()\n",
    "    predictions[~unrated_mask] = float('-inf')\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = torch.topk(predictions, n_recommendations)\n",
    "    top_movie_ids = user_movie_matrix.columns[indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommendations = movies_df[movies_df['movieId'].isin(top_movie_ids)]\n",
    "    return recommendations[['movieId', 'title', 'genres']]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Matrix Factorization using Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train SVD model\n",
    "svd_model = SVD(n_factors=100, random_state=42)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Convert SVD matrices to GPU tensors once\n",
    "svd_pu = torch.tensor(svd_model.pu, device=device, dtype=torch.float32)\n",
    "svd_qi = torch.tensor(svd_model.qi, device=device, dtype=torch.float32)\n",
    "svd_bu = torch.tensor(svd_model.bu, device=device, dtype=torch.float32)\n",
    "svd_bi = torch.tensor(svd_model.bi, device=device, dtype=torch.float32)\n",
    "svd_mu = torch.tensor([svd_model.trainset.global_mean], device=device, dtype=torch.float32)\n",
    "\n",
    "def matrix_factorization_recommender(user_id, n_recommendations=10):\n",
    "    # Get all movies that are in the trainset\n",
    "    all_movies = set(svd_model.trainset._raw2inner_id_items.keys())\n",
    "    \n",
    "    # Get user's rated movies\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    \n",
    "    # Get unrated movies that are in the trainset\n",
    "    unrated_movies = np.array(list(all_movies - set(rated_movies)))\n",
    "    \n",
    "    # Get user index in SVD model\n",
    "    user_inner_id = svd_model.trainset.to_inner_uid(user_id)\n",
    "    \n",
    "    # Get movie indices in SVD model (all are guaranteed to be in trainset now)\n",
    "    movie_inner_ids = unrated_movies  # Already in inner ids from trainset\n",
    "    \n",
    "    # Convert to GPU tensors\n",
    "    user_factors = svd_pu[user_inner_id]\n",
    "    movie_factors = svd_qi[movie_inner_ids]\n",
    "    user_bias = svd_bu[user_inner_id]\n",
    "    movie_biases = svd_bi[movie_inner_ids]\n",
    "    \n",
    "    # Calculate predictions on GPU\n",
    "    predictions = torch.matmul(user_factors, movie_factors.T) + user_bias + movie_biases + svd_mu\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = torch.topk(predictions, n_recommendations)\n",
    "    recommended_movie_ids = [unrated_movies[idx] for idx in indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]\n",
    "    return recommended_movies[['title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hybrid Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def hybrid_recommender(user_id, movie_title, n_recommendations=10):\n",
    "    # Get movie index for content-based\n",
    "    movie_idx = movies_with_tags[movies_with_tags['title'] == movie_title].index[0]\n",
    "    query_vector = get_cached_movie_features(movie_idx)\n",
    "    \n",
    "    # Get user features for collaborative\n",
    "    user_idx = user_movie_matrix.index.get_loc(user_id)\n",
    "    user_features = latent_matrix_2_gpu[user_idx]\n",
    "    user_ratings = torch.tensor(user_movie_matrix.loc[user_id].values, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # Get all valid movie indices\n",
    "    all_movies = set(svd_model.trainset._raw2inner_id_items.keys())\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    unrated_movies = np.array(list(all_movies - set(rated_movies)))\n",
    "    \n",
    "    # Compute content-based similarities\n",
    "    content_similarities = torch.nn.functional.cosine_similarity(\n",
    "        query_vector.unsqueeze(0).unsqueeze(0),\n",
    "        latent_matrix_gpu.unsqueeze(0)\n",
    "    ).squeeze()\n",
    "    \n",
    "    # Compute collaborative filtering scores\n",
    "    collab_predictions = torch.matmul(user_features, components_gpu)\n",
    "    \n",
    "    # Compute matrix factorization scores\n",
    "    user_inner_id = svd_model.trainset.to_inner_uid(user_id)\n",
    "    user_factors = svd_pu[user_inner_id]\n",
    "    movie_factors = svd_qi[unrated_movies]\n",
    "    movie_biases = svd_bi[unrated_movies]\n",
    "    mf_predictions = torch.matmul(user_factors, movie_factors.T) + svd_bu[user_inner_id] + movie_biases + svd_mu\n",
    "    \n",
    "    # Normalize scores to [0,1] range\n",
    "    content_scores = (content_similarities - content_similarities.min()) / (content_similarities.max() - content_similarities.min())\n",
    "    collab_scores = (collab_predictions - collab_predictions.min()) / (collab_predictions.max() - collab_predictions.min())\n",
    "    mf_scores = (mf_predictions - mf_predictions.min()) / (mf_predictions.max() - mf_predictions.min())\n",
    "    \n",
    "    # Get indices of unrated movies in the full movie list\n",
    "    movie_indices = np.array([movies_df[movies_df['movieId'] == mid].index[0] for mid in unrated_movies])\n",
    "    \n",
    "    # Combine scores with weights (only for unrated movies)\n",
    "    combined_scores = (\n",
    "        content_scores[movie_indices] * 0.3 + \n",
    "        collab_scores[movie_indices] * 0.4 + \n",
    "        mf_scores * 0.3\n",
    "    )\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, top_indices = combined_scores.topk(n_recommendations)\n",
    "    recommended_indices = movie_indices[top_indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df.iloc[recommended_indices][['movieId', 'title', 'genres']]\n",
    "    recommended_movies['scores'] = combined_scores[top_indices].cpu().numpy()\n",
    "    recommended_movies['content_score'] = content_scores[movie_indices][top_indices].cpu().numpy()\n",
    "    recommended_movies['collab_score'] = collab_scores[movie_indices][top_indices].cpu().numpy()\n",
    "    recommended_movies['mf_score'] = mf_scores[top_indices].cpu().numpy()\n",
    "    \n",
    "    # Cache the results\n",
    "    cache.set(f\"hybrid_{user_id}_{movie_title}\", recommended_indices)\n",
    "    \n",
    "    return recommended_movies.sort_values('scores', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas display options for wide tables                                                                                                                                    \n",
    "from tabulate import tabulate                                                                                                                           \n",
    "pd.set_option('display.max_columns', None)                                                                                                              \n",
    "pd.set_option('display.width', None)                                                                                                                    \n",
    "pd.set_option('display.max_colwidth', None)                                                                                                             \n",
    "                                                                                                                                                        \n",
    "def display_recommendations(df):                                                                                                                        \n",
    "    print(tabulate(df, headers='keys', tablefmt='pipe', showindex=False)) \n",
    "\n",
    "# Example usage\n",
    "print(\"Popular Movies:\")                                                                                                                                \n",
    "display_recommendations(popularity_recommender())                                                                                                       \n",
    "                                                                                                                                                        \n",
    "print(\"\\nContent-based Recommendations for 'Toy Story (1995)':\")                                                                                        \n",
    "display_recommendations(content_based_recommender('Toy Story (1995)'))                                                                                  \n",
    "                                                                                                                                                        \n",
    "print(\"\\nCollaborative Filtering Recommendations for user 1:\")                                                                                          \n",
    "display_recommendations(collaborative_recommender(1))                                                                                                   \n",
    "                                                                                                                                                        \n",
    "print(\"\\nMatrix Factorization Recommendations for user 1:\")                                                                                             \n",
    "display_recommendations(matrix_factorization_recommender(1))                                                                                            \n",
    "                                                                                                                                                        \n",
    "print(\"\\nHybrid Recommendations for user 1 and 'Toy Story (1995)':\")                                                                                    \n",
    "result = await hybrid_recommender(1, 'Toy Story (1995)')                                                                                                \n",
    "display_recommendations(result)                                                                                                                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
