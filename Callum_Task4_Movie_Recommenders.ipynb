{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender Systems\n",
    "\n",
    "This notebook implements various movie recommendation approaches:\n",
    "1. Popularity-based\n",
    "2. Content-based Filtering\n",
    "3. Collaborative Filtering\n",
    "4. Matrix Factorization\n",
    "5. Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasets\n",
    "movies_df = pd.read_csv('ml-latest-small/movies.csv')\n",
    "ratings_df = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "tags_df = pd.read_csv('ml-latest-small/tags.csv')\n",
    "\n",
    "# Merge tags for each movie\n",
    "tags_grouped = tags_df.groupby('movieId')['tag'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "movies_with_tags = pd.merge(movies_df, tags_grouped, on='movieId', how='left')\n",
    "movies_with_tags['tag'] = movies_with_tags['tag'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Popularity-based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_recommender(n_recommendations=10):\n",
    "    # Calculate mean rating and number of ratings for each movie\n",
    "    movie_stats = ratings_df.groupby('movieId').agg({\n",
    "        'rating': ['count', 'mean']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns\n",
    "    movie_stats.columns = ['movieId', 'rating_count', 'rating_mean']\n",
    "    \n",
    "    # Filter movies with minimum number of ratings (e.g., 100)\n",
    "    popular_movies = movie_stats[movie_stats['rating_count'] >= 100]\n",
    "    \n",
    "    # Sort by rating mean and count\n",
    "    popular_movies = popular_movies.sort_values(['rating_mean', 'rating_count'], ascending=[False, False])\n",
    "    \n",
    "    # Get movie titles\n",
    "    recommendations = pd.merge(popular_movies, movies_df, on='movieId')\n",
    "    \n",
    "    return recommendations[['title', 'rating_mean', 'rating_count']].head(n_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Create document-term matrix\n",
    "tfidf_matrix = tfidf.fit_transform(movies_with_tags['tag'])\n",
    "\n",
    "# Perform dimensionality reduction using TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "latent_matrix_1 = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Convert latent matrix to GPU tensor once\n",
    "latent_matrix_gpu = torch.tensor(latent_matrix_1, device=device, dtype=torch.float32)\n",
    "\n",
    "def content_based_recommender(movie_title, n_recommendations=10):\n",
    "    # Get movie index\n",
    "    movie_idx = movies_with_tags[movies_with_tags['title'] == movie_title].index[0]\n",
    "    \n",
    "    # Get query vector\n",
    "    query_vector = latent_matrix_gpu[movie_idx].unsqueeze(0)\n",
    "    \n",
    "    # Calculate similarity scores on GPU\n",
    "    similarities = torch.nn.functional.cosine_similarity(\n",
    "        query_vector.unsqueeze(0), \n",
    "        latent_matrix_gpu.unsqueeze(1)\n",
    "    ).squeeze()\n",
    "    \n",
    "    # Get top similar movies\n",
    "    _, similar_indices = similarities.topk(n_recommendations + 1)\n",
    "    similar_indices = similar_indices[1:].cpu().numpy()  # Exclude the query movie\n",
    "    \n",
    "    return movies_with_tags.iloc[similar_indices][['title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-movie matrix\n",
    "user_movie_matrix = ratings_df.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Perform SVD for collaborative filtering\n",
    "svd_collab = TruncatedSVD(n_components=100)\n",
    "latent_matrix_2 = svd_collab.fit_transform(user_movie_matrix)\n",
    "\n",
    "# Convert matrices to GPU tensors once\n",
    "latent_matrix_2_gpu = torch.tensor(latent_matrix_2, device=device, dtype=torch.float32)\n",
    "components_gpu = torch.tensor(svd_collab.components_, device=device, dtype=torch.float32)\n",
    "\n",
    "def collaborative_recommender(user_id, n_recommendations=10):\n",
    "    # Get user's latent features\n",
    "    user_idx = user_movie_matrix.index.get_loc(user_id)\n",
    "    user_features = latent_matrix_2_gpu[user_idx]\n",
    "    user_ratings = torch.tensor(user_movie_matrix.loc[user_id].values, device=device)\n",
    "    \n",
    "    # Calculate predicted ratings on GPU\n",
    "    predicted_ratings = torch.matmul(user_features, components_gpu)\n",
    "    \n",
    "    # Create mask for unrated movies\n",
    "    unrated_mask = (user_ratings == 0)\n",
    "    \n",
    "    # Set rated movies to negative infinity to exclude them\n",
    "    predictions = predicted_ratings.clone()\n",
    "    predictions[~unrated_mask] = float('-inf')\n",
    "    \n",
    "    # Get top recommendations\n",
    "    _, indices = torch.topk(predictions, n_recommendations)\n",
    "    top_movie_ids = user_movie_matrix.columns[indices.cpu().numpy()]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin(top_movie_ids)]\n",
    "    return recommended_movies[['title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Matrix Factorization using Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Train SVD model\n",
    "svd_model = SVD(n_factors=100, random_state=42)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "def matrix_factorization_recommender(user_id, n_recommendations=10):\n",
    "    # Get all movies\n",
    "    all_movies = movies_df['movieId'].unique()\n",
    "    \n",
    "    # Get user's rated movies\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    \n",
    "    # Get unrated movies\n",
    "    unrated_movies = np.setdiff1d(all_movies, rated_movies)\n",
    "    \n",
    "    # Predict ratings for unrated movies\n",
    "    predictions = [svd_model.predict(user_id, movie_id) for movie_id in unrated_movies]\n",
    "    \n",
    "    # Sort predictions\n",
    "    sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:n_recommendations]\n",
    "    \n",
    "    # Get recommended movies\n",
    "    recommended_movies = movies_df[movies_df['movieId'].isin([pred.iid for pred in sorted_predictions])]\n",
    "    \n",
    "    return recommended_movies[['title', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hybrid Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommender(user_id, movie_title, n_recommendations=10):\n",
    "    # Get recommendations from each method\n",
    "    content_recs = content_based_recommender(movie_title, n_recommendations)\n",
    "    collab_recs = collaborative_recommender(user_id, n_recommendations)\n",
    "    mf_recs = matrix_factorization_recommender(user_id, n_recommendations)\n",
    "    \n",
    "    # Combine recommendations\n",
    "    all_recs = pd.concat([\n",
    "        content_recs.assign(method='content'),\n",
    "        collab_recs.assign(method='collaborative'),\n",
    "        mf_recs.assign(method='matrix_factorization')\n",
    "    ])\n",
    "    \n",
    "    # Remove duplicates and sort by frequency of appearance\n",
    "    final_recs = all_recs.groupby('title').agg({\n",
    "        'genres': 'first',\n",
    "        'method': lambda x: ', '.join(x)\n",
    "    }).reset_index()\n",
    "    \n",
    "    final_recs['recommendation_strength'] = final_recs['method'].str.count(',')\n",
    "    \n",
    "    return final_recs.sort_values('recommendation_strength', ascending=False).head(n_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "print(\"Popular Movies:\")\n",
    "print(popularity_recommender())\n",
    "\n",
    "print(\"\\nContent-based Recommendations for 'Toy Story (1995)':\")\n",
    "print(content_based_recommender('Toy Story (1995)'))\n",
    "\n",
    "print(\"\\nCollaborative Filtering Recommendations for user 1:\")\n",
    "print(collaborative_recommender(1))\n",
    "\n",
    "print(\"\\nMatrix Factorization Recommendations for user 1:\")\n",
    "print(matrix_factorization_recommender(1))\n",
    "\n",
    "print(\"\\nHybrid Recommendations for user 1 and 'Toy Story (1995)':\")\n",
    "print(hybrid_recommender(1, 'Toy Story (1995)'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
